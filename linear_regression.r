# Day 1 - Load built-in dataset
data(mtcars)
head(mtcars)

# to see a summary of each column (min, median, mean, max)
summary(mtcars)

# to see relationships between columns
cor(mtcars$mpg, mtcars$wt) ## to see how mpg relates/reacts to weight
cor(mtcars$mpg, mtcars$hp) ## to see how mpg relates/reacts to horsepower

# to visualize a relationship
plot (mtcars$wt, mtcars$mpg
      ,main = "MPG vs Weight"
      ,xlab = "Weight (1000 lbs)"
      ,ylab = "Miles per Gallon"
      ,pch = 19
      ,col= "steelblue")

# Fit the linear regression model
model <- lm(mpg ~ wt, data = mtcars)
  ## mpg is first because, we are evaluating how it reacts to weight

# View the summary of the model
summary(model)

## A result is statistically significant when it is very unlikely to have occurred by chance, assuming there's no real effect.

##If the predictor (e.g., wt) is statistically significant:
  ##You can be confident there's a real relationship between wt and mpg

##The negative slope (‚àí5.34) isn't just noise ‚Äî it's likely a real effect

##You‚Äôre not just seeing a random pattern in the data

##üß† Rule of Thumb (for p-values)
##p-value	Meaning
##< 0.001	‚úÖ Very strong evidence (*** in output)
##< 0.01	‚úÖ Strong evidence (** in output)
##< 0.05	‚úÖ Acceptable evidence (* in output)
##> 0.05	‚ùå Not statistically significant

##This means:
  
  ##R-squared = 0.75 ‚Üí 75% of the variation in MPG can be explained by car weight.

##The remaining 25% is due to other factors not in the model (e.g., horsepower, engine size, aerodynamics, etc.)

##‚úÖ Rules of Thumb (Context Matters)
##R-squared Value	Interpretation
##0.90 ‚Äì 1.00	Excellent fit (very rare in real-world data)
##0.70 ‚Äì 0.89	Good fit ‚Äî your model explains most variation
##0.40 ‚Äì 0.69	Moderate ‚Äî might be useful, but other variables missing
##< 0.40	Weak model ‚Äî probably needs more predictors

##üîç In social sciences, 0.3‚Äì0.5 might still be valuable. In manufacturing or physics, you often want 0.8+.

##üí° In your case:
  ##If R¬≤ = 0.75, that's strong: weight is a strong predictor of mpg, but not the only one.

##It tells your stakeholders: ‚ÄúWe can explain ~75% of mpg variation using just weight.‚Äù


# Basic residual plot
plot(model$residuals,
     main = "Residuals from Linear Model",
     ylab = "Residuals (Error)",
     xlab = "Index",
     pch = 19,
     col = "darkorange")

abline(h = 0, lty = 2, col = "gray")

# -------------------------------------------------------------
# üìä Residual Plot Interpretation Guide (Reference Notes)
# -------------------------------------------------------------

# ‚úÖ What Residuals Should Look Like:
# ‚Ä¢ Randomly scattered around 0
# ‚Ä¢ No clear pattern, shape, or trend
# ‚Ä¢ Roughly equal spread (homoscedasticity)

# üö© Common Residual Patterns and What They Mean:

# 1. Curve Shape:
# - Meaning: Non-linear relationship not captured by linear model
# - Fix: Try polynomial regression (e.g., add I(x^2)) or use non-linear models

# 2. Funnel Shape (widening or narrowing spread):
# - Meaning: Heteroscedasticity (changing variance)
# - Fix: Log or sqrt transform the dependent variable (e.g., log(y)), or use WLS

# 3. Big Outliers:
# - Meaning: Individual points are influencing the model too much
# - Fix: Investigate data, use robust regression (e.g., MASS::rlm), or exclude outliers

# 4. Clear Groups or Stripes:
# - Meaning: Missing a categorical variable or subgroup structure
# - Fix: Add categorical variables (e.g., factor(type)), or model groups separately

# üß™ Bonus Diagnostic Plots in R:
# - Residuals vs Fitted: plot(model)
# - Q-Q Plot: qqnorm(resid(model)); qqline(resid(model))
# - Influence Plot: car::influencePlot(model)


#Goal: Model mpg as a function of wt using simple linear regression.

#Key findings: Slope was negative (heavier cars ‚Üí lower mpg). R¬≤ ‚âà ____ (explain what % of variance weight explains).

#Significance: p‚Äëvalue for wt < 0.05, so relationship is statistically significant.

#Diagnostics: Residuals centered around 0 with no strong pattern ‚Üí linearity/constant variance looked ok.

#Limitations: Single predictor; likely missing factors (hp, cylinders, etc.).

#Next step: Try mpg ~ wt + hp and/or polynomial term I(wt^2); compare R¬≤ and residuals.


# -------------------------------------------------------------
# üìì Week 1 Reflection ‚Äì Linear Regression (Learning Summary)
# -------------------------------------------------------------
# This week I learned how to approach and interpret a simple linear regression model
# in R using the mtcars dataset, focusing on mpg (dependent variable) and weight (independent variable).
#
# 1Ô∏è‚É£ Data exploration
# - Used summary() to see min, median, mean, and max for each variable.
# - Used cor() to measure relationships: mpg has a strong negative correlation with weight and horsepower.
# - Visualized mpg vs weight with a scatter plot, learning how pch and col control point style and color.
#
# 2Ô∏è‚É£ Model creation
# - Fitting the model with lm(mpg ~ wt) taught me that the dependent variable (mpg) goes first
#   because we are modeling how it reacts to the independent variable (weight).
# - The model output showed an intercept and slope, which form the equation to predict mpg from weight.
#
# 3Ô∏è‚É£ Statistical significance
# - A predictor is statistically significant if its p-value is < 0.05, meaning the observed effect
#   is unlikely to have happened by chance.
# - In this model, weight‚Äôs slope was negative and highly significant (p-value ‚â™ 0.001),
#   indicating a real and strong relationship: heavier cars tend to get lower mpg.
#
# 4Ô∏è‚É£ R-squared interpretation
# - R¬≤ = 0.75 means 75% of the variation in mpg can be explained by weight alone.
# - The remaining 25% comes from other variables not in the model (e.g., horsepower, engine size, aerodynamics).
# - Good practice: In manufacturing/physics, aim for R¬≤ ‚â• 0.8; in social sciences, 0.3‚Äì0.5 can still be valuable.
#
# 5Ô∏è‚É£ Residual plots
# - Residuals are the differences between actual and predicted values.
# - A well-behaved residual plot shows points scattered randomly around 0 with no pattern.
# - Learned to diagnose patterns:
#   ‚Ä¢ Curve shape ‚Üí add polynomial terms or use non-linear models
#   ‚Ä¢ Funnel shape ‚Üí variance changes, consider log/sqrt transforms or weighted regression
#   ‚Ä¢ Outliers ‚Üí investigate or use robust regression
#   ‚Ä¢ Clusters ‚Üí missing categorical variable
#
# 6Ô∏è‚É£ Key takeaway
# - Linear regression is not just drawing a line ‚Äî it‚Äôs building a predictive model backed by statistics.
# - Understanding p-values, R¬≤, and residual behavior helps confirm whether the model is valid,
#   and informs when to try transformations, add predictors, or switch modeling approaches.
# -------------------------------------------------------------
